# Transformer
- Embedding
    - Encoder
    - Decoder
- Attention
    - Muti-Head Attention
    - Self-Attention

## Embedding
### Encoder
- Many to One
- 아날로그 신호에서 디지털 신호로 변환
    - "나는 학생이야" 라고 말하면 인간은 알아들을수 있지만 컴퓨터는 못알아 듣는다.
    - 컴퓨터는 "나는 학생이야" (아날로그)를 전혀 해석할 수 없으므로 이를 디지털신호(숫자)로 바꾸기 위해 이를 Encoder로 변환해야 한다
### Decoder
- One to Many
- 디지털 신호에서 아날로그 신호로 변환
    - 중간단계인 전처리 과정을 완료 후 이를 다시 아날로그 신호로 변환하기 위해 이를 Decoder로 변환해야 한다.

## Attention
- Query as q : 질문
- Key as k : 대답
- Value as v : 대답의 내용
자세한 설명은 생략

### Self-Attention
- 자신과의 관계를 계산한다. "I am student"를 list()함수로 변환하면 ['I','am','student'] 이면 'I'는 'am', 'student'관계측정, 'am'은 'I', 'student'관계측정, 'student'은 'I', 'am' 이런식으로 모두 측정한다.
- q = k = v 식이 성립되어야 한다

### Muti-Head Attention
- 예시로 똑같은 사람이 있고 한 논문을 각자 읽어서 토론을 한다. => 내가 모르는 부분이 다른사람이 알고, 다른사람이 모르는 부분은 내가 다른사람에게 알려주는 거라고 이해하면된다.
- 위의 예시로 한사람 당 Q, K, V가 있다면 여러사람에 대한 각각 Q, K, V가 있다. 이를 통해 각각에 대한 가중치(W)를 구하고 모은 결과값을 flatten()화 시켜서 Softmax함수를 구해서 값을 얻을 수 있다.
  
